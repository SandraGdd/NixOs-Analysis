{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22eca2c-9a7e-475c-977a-4ca2bfa9534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b92e16-0ffa-4892-80e1-830e10a30788",
   "metadata": {},
   "outputs": [],
   "source": [
    "owner = 'NixOS'  \n",
    "repo = 'nixpkgs' \n",
    "\n",
    "url = f'https://api.github.com/repos/{owner}/{repo}/commits'    #endpoint commits\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc8445-4dff-4dda-be75-d8b93c0b6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get companies from GitHub, try with 1000 commits \n",
    "\n",
    "TOKEN = ''   #GitHub API Token\n",
    "\n",
    "# Repository:\n",
    "owner = 'NixOS'\n",
    "repo = 'nixpkgs'\n",
    "url = f'https://api.github.com/repos/{owner}/{repo}/commits?per_page=10'   # Limit at 10 commits per request\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'token {TOKEN}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "# initialze dataframe \n",
    "commit_data = pd.DataFrame(columns=['Email', 'Timestamp', 'Company'])  \n",
    "\n",
    "commit_limit = 1000  # limit \n",
    "commit_count = 0\n",
    "\n",
    "# commit function\n",
    "def get_commits(url):\n",
    "    global commit_count\n",
    "    global commit_data\n",
    "\n",
    "    while url and commit_count < commit_limit:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        try:\n",
    "            response.raise_for_status()\n",
    "            commits = response.json()\n",
    "\n",
    "            for commit in commits:\n",
    "                if commit_count >= commit_limit:\n",
    "                    break\n",
    "                author_url = commit['author']['url'] if commit['author'] else None\n",
    "                email = commit['commit']['author']['email']\n",
    "                timestamp = commit['commit']['author']['date']\n",
    "                company = None\n",
    "\n",
    "                # if author_url: vorhanden ist, try and get profilinfo for comopanyname\n",
    "                if author_url:\n",
    "                    user_response = requests.get(author_url, headers=headers)\n",
    "                    if user_response.status_code == 200:\n",
    "                        user_data = user_response.json()\n",
    "                        company = user_data.get('company')  \n",
    "\n",
    "                # append in df\n",
    "                commit_data.loc[commit_count] = [email, timestamp, company]\n",
    "                commit_count += 1\n",
    "\n",
    "            # check next page\n",
    "            url = response.links.get('next', {}).get('url')\n",
    "\n",
    "            # waiting time between requests\n",
    "            time.sleep(1)\n",
    "\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(f'HTTP Error: {err}')\n",
    "            break\n",
    "\n",
    "\n",
    "get_commits(url)\n",
    "\n",
    "commit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f19af6-a7ab-4a65-b797-3cd177e6ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_data['Company'] = commit_data['Company'].str.replace('@', '', regex=False) #performs simple, direct string replacement(default r=True)\n",
    "commit_data['Company'] = commit_data['Company'].str.strip()\n",
    "commit_data['Company'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ed421b-14ef-41e1-8cf2-522e98e58b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting commitinfos for 2024\n",
    "\n",
    "TOKEN = ''\n",
    "# Repository\n",
    "owner = 'NixOS'\n",
    "repo = 'nixpkgs'\n",
    "url = f'https://api.github.com/repos/{owner}/{repo}/commits?per_page=100'  # limit 10 commits per request\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'token {TOKEN}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "start_date = datetime(2024, 1, 1)  # time limit 2024\n",
    "end_date = datetime(2024, 6, 6)  \n",
    "\n",
    "params = {\n",
    "    'since': start_date.isoformat() + 'Z',  #UTC timezone\n",
    "    'until': end_date.isoformat() + 'Z'      \n",
    "}\n",
    "\n",
    "df24 = pd.DataFrame(columns=['Email', 'Timestamp', 'Company']) # initialise datset\n",
    "\n",
    "def get_commits(url):    #function get info\n",
    "    global commit_count\n",
    "    global df24\n",
    "\n",
    "    while url:\n",
    "        response = requests.get(url, headers=headers, params=params)  # parameter:timelimit\n",
    "        \n",
    "        try:\n",
    "            response.raise_for_status()\n",
    "            commits = response.json()\n",
    "\n",
    "            for commit in commits:\n",
    "                author_url = commit['author']['url'] if commit['author'] else None\n",
    "                email = commit['commit']['author']['email']\n",
    "                timestamp = commit['commit']['author']['date']\n",
    "                company = None\n",
    "\n",
    "                # if there is author: get info\n",
    "                if author_url:\n",
    "                    user_response = requests.get(author_url, headers=headers)\n",
    "                    if user_response.status_code == 200:\n",
    "                        user_data = user_response.json()\n",
    "                        company = user_data.get('company')  \n",
    "\n",
    "                # add to df\n",
    "                df24.loc[commit_count] = [email, timestamp, company]\n",
    "                commit_count += 1\n",
    "\n",
    "            # check if there is a next page\n",
    "            url = response.links.get('next', {}).get('url')\n",
    "\n",
    "            # waiting time between requests\n",
    "            time.sleep(1)\n",
    "\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(f'HTTP Error: {err}')\n",
    "            break\n",
    "\n",
    "\n",
    "get_commits(url)\n",
    "\n",
    "df24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c926fee-03ab-4d2b-a3c5-a2f97936f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d022f0-ad13-44ec-99ff-a988a708a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub API Token\n",
    "TOKEN = ''  # Ersetze dies durch dein API-Token\n",
    "\n",
    "# Repository-Informationen\n",
    "owner = 'NixOS'\n",
    "repo = 'nixpkgs'\n",
    "url = f'https://api.github.com/repos/{owner}/{repo}/commits?per_page=100'\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'token {TOKEN}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "start_date = datetime(2024, 1, 1)  # Zeitlimit für 2024\n",
    "end_date = datetime.utcnow()  \n",
    "\n",
    "params = {\n",
    "    'since': start_date.isoformat() + 'Z',  # Startdatum\n",
    "    'until': end_date.isoformat() + 'Z'      # Enddatum\n",
    "}\n",
    "\n",
    "# DataFrame nur für die Unternehmensnamen initialisieren\n",
    "df_companies = pd.DataFrame(columns=['Timestamp', 'Company'])  # E-Mail-Spalte entfernt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d5054-9f45-4f95-986f-d5e2979b951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits(url):\n",
    "    results = []  # Liste zur Speicherung der Ergebnisse\n",
    "    while url:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        print(f'Sending request to: {url}')  # Debugging\n",
    "        print(f'Status Code: {response.status_code}')  # Debugging\n",
    "        \n",
    "        try:\n",
    "            response.raise_for_status()\n",
    "            commits = response.json()\n",
    "            print(f'Found {len(commits)} commits')  # Debugging\n",
    "            \n",
    "            if not commits:\n",
    "                print('No commits found for this request.')\n",
    "                break\n",
    "\n",
    "            for commit in commits:\n",
    "                timestamp = commit['commit']['author']['date']  # Zeitstempel speichern\n",
    "                company = None  # Unternehmensname initialisieren\n",
    "                author_url = commit['author']['url'] if commit['author'] else None\n",
    "\n",
    "                # Wenn ein Author-URL vorhanden ist, versuche, die Unternehmensdaten abzurufen\n",
    "                if author_url:\n",
    "                    user_response = requests.get(author_url, headers=headers)\n",
    "                    if user_response.status_code == 200:\n",
    "                        company = user_response.json().get('company')  # Unternehmensname abrufen\n",
    "\n",
    "                # Ergebnis zur Liste hinzufügen\n",
    "                results.append([timestamp, company if company else 'None'])\n",
    "\n",
    "            # Überprüfen, ob es eine nächste Seite gibt\n",
    "            url = response.links.get('next', {}).get('url')\n",
    "            time.sleep(1)  # Wartezeit zwischen den Anfragen\n",
    "\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(f'HTTP Error: {err}')\n",
    "            break\n",
    "\n",
    "    # Konvertiere die Ergebnisse in einen DataFrame\n",
    "    global df_companies  # Setze die globale DataFrame-Variable\n",
    "    df_companies = pd.DataFrame(results, columns=['Timestamp', 'Company'])\n",
    "\n",
    "# Aufrufen der Funktion\n",
    "get_commits(url)\n",
    "\n",
    "# Ausgabe des DataFrames\n",
    "print(df_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502acecc-ff67-481d-aca0-f6b6ac724143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5b55b-a6ba-490d-b87d-7e28fe8b3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24= df24.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09b912-f1f3-41ba-80b7-4974e1de3a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695be5e-0737-4eae-a395-a8c9a517ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24['Company'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a1b61-cd35-492b-ad8e-e3dc8e229583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24['Company'] = df24['Company'].str.replace('@', '', regex=False) #performs simple, direct string replacement(default r=True)\n",
    "df24['Company'] = df24['Company'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022fe912-3002-4c9d-b971-5dcaa69ae6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24['Company'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d3c34-db41-4c43-9007-da59a1fb5167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
